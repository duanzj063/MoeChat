# MoeChat 记忆体系统技术文档

## 📋 目录

- [系统架构概览](#系统架构概览)
- [核心记忆系统](#核心记忆系统)
- [长期记忆系统](#长期记忆系统)
- [知识库系统](#知识库系统)
- [技术亮点与创新](#技术亮点与创新)
- [性能优化机制](#性能优化机制)
- [配置与扩展](#配置与扩展)

---

## 🏗️ 系统架构概览

MoeChat采用了创新的三层记忆架构，模拟人类记忆系统的不同层次：

```
┌─────────────────────────────────────────────────────────────┐
│                    MoeChat 三层记忆系统                       │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐ │
│  │   核心记忆      │  │   长期记忆      │  │   知识库        │ │
│  │  Core Memory    │  │ Long-term Memory│  │ Knowledge Base │ │
│  │                 │  │                 │  │                 │ │
│  │ • 重要用户信息   │  │ • 日常对话记录   │  │ • 背景知识      │ │
│  │ • 关键事件      │  │ • 时间序列数据   │  │ • 世界设定      │ │
│  │ • 个人偏好      │  │ • 情感状态      │  │ • 角色设定      │ │
│  │ • FAISS向量索引 │  │ • YAML文件存储   │  │ • FAISS索引     │ │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### 🔄 记忆流动机制

1. **实时对话** → **长期记忆** (自动记录日记)
2. **长期记忆** → **核心记忆** (LLM提取重要信息)
3. **知识库** → **上下文增强** (检索相关背景知识)
4. **多源记忆** → **对话生成** (综合所有记忆层)

---

## 🧠 核心记忆系统 (Core Memory)

### 📁 文件结构
```
./data/agents/{char}/core_mem.yml
```

### 🎯 设计目标
- 存储用户的重要个人信息和关键事件
- 提供快速的语义搜索能力
- 支持增量更新和持久化存储

### 🔧 核心组件

#### 1. 数据结构设计
```python
class Core_Mem:
    def __init__(self):
        self.mems = []        # 记忆文本列表
        self.msgs = []        # 格式化记忆信息
        self.uuid = []        # 唯一标识符列表
        self.index = None     # FAISS向量索引
```

#### 2. 记忆存储格式
```yaml
# core_mem.yml 示例
Xk9B2cD8E7:
  time: "2024-01-15 14:30:25"
  text: "用户喜欢看电影，特别是科幻片"
A3fG7hJ9k2:
  time: "2024-01-16 09:15:42" 
  text: "用户的工作是软件工程师"
```

#### 3. 向量化与索引构建
```python
# 使用FAISS构建内积相似度索引
vects = embedding.t2vect(self.mems)
self.index = faiss.IndexFlatIP(len(vects[0]))
self.index.add(vects)
```

### 🚀 核心功能

#### 1. 记忆检索 (`find_mem`)
- **输入**: 用户查询文本
- **处理**: 向量化 → FAISS搜索 → 阈值过滤
- **输出**: 相关记忆列表 (相似度 ≥ 0.5)

```python
def find_mem(self, msg: str, res_msg: list):
    D, I = self.index.search(embedding.t2vect([msg]), 5)
    for score, idx in zip(D[0], I[0]):
        if score >= self.thresholds:
            msg += self.msgs[idx] + "\n"
```

#### 2. 记忆添加 (`add_memory`)
- **UUID生成**: 使用shortuuid生成唯一标识
- **时间戳**: 记录记忆获取时间
- **增量更新**: 动态添加到向量索引

```python
def add_memory(self, msg: list):
    for m in msg:
        uuid = shortuuid.ShortUUID().random(length=10)
        t_n = time.strftime("%Y-%m-%d %H:%M:%S")
        m_list[uuid] = {"time": t_n, "text": m}
    
    # 增量向量更新
    vects = embedding.t2vect(msg)
    self.index.add(vects)
```

#### 3. 智能记忆提取
通过LLM分析对话内容，自动提取重要信息为核心记忆：

```python
def insert_core_mem(self, msg2: str, msg3: str, msg1: str):
    # 使用最近100条记忆作为上下文
    context = json.dumps(self.Core_mem.mems[-100:])
    
    # LLM提取重要信息
    res = requests.post(api_url, json={
        "model": self.llm_config["model"],
        "messages": [
            {"role": "system", "content": extraction_prompt},
            {"role": "user", "content": conversation}
        ]
    })
    
    # 解析并添加提取的记忆
    mem_list = ast.literal_eval(extracted_memories)
    if len(mem_list) > 0:
        self.Core_mem.add_memory(mem_list)
```

### 💡 技术亮点

1. **永久存储**: 所有核心记忆持久化保存，确保信息不丢失
2. **语义搜索**: 基于FAISS的高效向量相似度搜索
3. **增量更新**: 支持动态添加新记忆，无需重建索引
4. **UUID标识**: 避免重复，支持精确查找
5. **时间戳记录**: 每条记忆都有创建时间，便于追踪

---

## 📚 长期记忆系统 (Long-term Memory)

### 📁 文件结构
```
./data/agents/{char}/memorys/
├── 2024-01-15.yaml    # 按日期存储的对话记录
├── 2024-01-15.pkl     # 对应的向量缓存
├── 2024-01-16.yaml
└── 2024-01-16.pkl
```

### 🎯 设计目标
- 完整记录所有对话历史
- 支持基于时间范围的精确检索
- 提供语义级别的智能搜索

### 🔧 核心组件

#### 1. 数据结构设计
```python
class Memorys:
    def __init__(self):
        self.memorys_key = []    # 时间戳键列表 (已排序)
        self.memorys_data = {}   # 记忆数据字典
        self.vectors = []        # 标签向量列表
```

#### 2. 记忆存储格式
```yaml
# 2024-01-15.yaml 示例
1705320625:
  text_tag: "用户分享工作经历"
  msg: |
    时间：2024-01-15 14:30:25
    {{user}}：我今天在工作中遇到了一个有趣的问题
    {{char}}：什么问题呢？我很感兴趣听听
1705320756:
  text_tag: "日常闲聊"
  msg: |
    时间：2024-01-15 14:32:36
    {{user}}：今天天气真不错
    {{char}}：是的，适合出去走走
```

### 🚀 核心功能

#### 1. 时间实体识别与检索
```python
def get_memorys(self, msg: str, res_msg: list, t_n: str):
    # 使用jionlp提取时间实体
    res = jio.ner.extract_time(f"[{t_n}]{msg}", time_base=time.time())
    
    # 解析时间范围
    for t in res[1:]:
        res_t = jio.parse_time(t["text"], time_base=res[0]["text"])
        time_st1 = int(time.mktime(time.strptime(res_t["time"][0])))
        time_st2 = int(time.mktime(time.strptime(res_t["time"][1])))
        
    # 二分查找时间范围内的记忆
    res_index = self.find_range_indices(time_st1, time_st2)
```

#### 2. 高效的二分查找
```python
def find_range_indices(self, low, high) -> list:
    start_idx = bisect_left(self.memorys_key, low)
    end_idx = bisect_right(self.memorys_key, high)
    return [start_idx, end_idx-1]
```

#### 3. 智能记忆标签生成
通过LLM自动生成记忆标签，过滤日常闲聊：

```python
def add_memory1(self, data: list, t_n: int, llm_config: dict):
    # LLM生成记忆标签
    res = requests.post(llm_config["api"], json={
        "model": llm_config["model"],
        "messages": [
            {"role": "system", "content": tag_generation_prompt},
            {"role": "user", "content": user_message}
        ]
    })
    
    # 过滤日常闲聊
    res_tag = res.json()["choices"][0]["message"]["content"]
    if res_tag.find("日常闲聊") == -1:
        final_tag = res_tag
    else:
        final_tag = "日常闲聊"
```

#### 4. 增量向量缓存
```python
def add_memory(self, m_data: dict):
    # 生成标签向量
    tag_vector = embedding.t2vect([m_data["text_tag"]])[0]
    self.vectors.append(tag_vector)
    
    # 更新当日向量缓存
    day_time = t_n - (t_n - time.timezone) % 86400
    index = bisect_left(self.memorys_key, day_time)
    v_list = self.vectors[index:]
    
    # 保存pickle缓存
    with open(f"{date}.pkl", "wb") as f:
        pickle.dump(v_list, f)
```

### 💡 技术亮点

1. **时间序列存储**: 按日期组织，便于时间范围查询
2. **智能标签**: LLM自动生成记忆标签，提高检索精度
3. **二分查找**: O(log n)的时间复杂度进行时间范围查询
4. **向量缓存**: 每日向量独立缓存，避免重复计算
5. **语义过滤**: 基于相似度阈值过滤不相关记忆

---

## 📖 知识库系统 (Knowledge Base)

### 📁 文件结构
```
./data/agents/{char}/data_base/
├── world_books.yaml      # 世界书内容
├── tmp/
│   ├── labels/           # 向量缓存目录
│   │   ├── book1.pkl
│   │   └── book2.pkl
│   └── label.yaml        # 文件MD5记录
```

### 🎯 设计目标
- 存储角色背景知识和世界观设定
- 支持增量更新和缓存机制
- 提供高效的语义搜索能力

### 🔧 核心组件

#### 1. 世界书格式
```yaml
# world_books.yaml 示例
角色设定:
  name: "Chat酱"
  personality: "腹黑毒舌但温柔体贴"
  background: "手机器灵，随使用成长"

世界观:
  setting: "现代科技世界"
  magic_system: "基于科技的智能系统"
  
重要人物:
  user: "芙兰蠢兔，Chat酱的主人"
  friends: "其他AI助手"
```

#### 2. MD5文件检测
```python
def sum_md5(file_path: str):
    with open(file_path, 'rb') as file:
        md5_obj = hashlib.md5()
        while True:
            data = file.read(4096)
            if not data:
                break
            md5_obj.update(data)
    return md5_obj.hexdigest()
```

### 🚀 核心功能

#### 1. 增量更新机制
```python
def __init__(self):
    # 加载已处理文件的MD5记录
    base_list = {}
    try:
        with open("tmp/label.yaml", "r") as f:
            base_list = yaml.safe_load(f)
    except:
        base_list = {}
    
    # 检测新增或修改的文件
    for file in file_list:
        f_md5 = sum_md5(file_path)
        if file not in base_list or base_list[file] != f_md5:
            books.append(file)  # 需要重新处理的文件
```

#### 2. 向量化与缓存
```python
# 向量化新文件内容
for index in range(len(books)):
    with open(books_path[index], "r") as f:
        datas = yaml.safe_load(f)
        tmp1 = []  # 键列表
        tmp2 = []  # 值列表
        
        for data in datas:
            tmp1.append(data)           # 标题
            tmp2.append(datas[data])    # 内容
        
        # 向量化并缓存
        vect_list = embedding.t2vect(tmp1)
        res_data = {"vect": vect_list, "text": tmp2}
        
        with open(f"tmp/labels/{books[index]}.pkl", "wb") as f2:
            pickle.dump(res_data, f2)
```

#### 3. 合并索引构建
```python
# 合并所有向量数据
for file in file_list:
    with open(f"tmp/labels/{file}", "rb") as f:
        tmp_data = pickle.load(f)
    tmp_list.append(tmp_data["vect"])
    self.databases += tmp_data["text"]

# 构建FAISS索引
self.vects = np.concatenate(tmp_list)
self.index = faiss.IndexFlatIP(len(self.vects[0]))
self.index.add(self.vects)
```

#### 4. 语义搜索
```python
def search(self, text: list[str]) -> str:
    # 向量化查询文本
    vect = embedding.t2vect(text)
    
    # FAISS相似度搜索
    D, I = self.index.search(vect, self.top_k)
    
    # 阈值过滤
    for score, idx in zip(D[0], I[0]):
        if score >= self.thresholds:
            msg += self.databases[idx] + "\n\n"
    
    return msg
```

### 💡 技术亮点

1. **增量更新**: MD5检测文件变化，只处理新增或修改的内容
2. **智能缓存**: 向量化结果缓存，避免重复计算
3. **模块化设计**: 支持多个世界书文件，便于管理
4. **高效搜索**: FAISS向量索引，支持大规模数据检索
5. **容错处理**: 单个文件加载失败不影响整体系统

---

## ⭐ 技术亮点与创新

### 🚀 架构创新

#### 1. **三层记忆架构**
- **模拟人类记忆**: 短期记忆 → 长期记忆 → 知识库
- **专业化分工**: 不同类型数据使用最适合的存储方式
- **协同工作**: 多源信息融合，提供全面的上下文

#### 2. **智能信息提取**
```python
# 自动从对话中提取重要信息
对话内容 → LLM分析 → 重要信息提取 → 核心记忆存储
```

#### 3. **时间感知检索**
```python
# 支持自然语言时间查询
"昨天我们聊了什么？" → 时间实体识别 → 时间范围检索 → 结果返回
```

### 🔧 性能优化

#### 1. **向量化缓存策略**
- **按需计算**: 首次使用时向量化，后续直接加载缓存
- **增量更新**: 新增记忆时只向量化新增内容
- **分层缓存**: 日级缓存 + 全局索引

#### 2. **高效搜索算法**
- **FAISS索引**: 百万级向量毫秒级搜索
- **二分查找**: O(log n)时间复杂度的时间范围查询
- **相似度过滤**: 基于阈值的精确结果过滤

#### 3. **内存优化**
- **懒加载**: 按需加载记忆数据，减少内存占用
- **分片存储**: 大数据量分文件存储，便于管理
- **向量复用**: 多个搜索共享向量索引

### 💾 数据管理

#### 1. **持久化设计**
```python
# 所有数据都有对应的持久化存储
内存数据 → 磁盘文件 → 程序重启 → 自动恢复
```

#### 2. **数据完整性**
- **事务性写入**: 确保数据写入的原子性
- **备份机制**: YAML格式便于人工检查和修复
- **错误恢复**: 单点故障不影响整体系统

#### 3. **扩展性设计**
- **插件化**: 支持新的记忆类型扩展
- **配置化**: 通过配置文件灵活调整参数
- **接口化**: 标准化的增删改查接口

---

## ⚙️ 性能优化机制

### 🚀 向量化优化

#### 1. **缓存策略**
```python
# 三级缓存机制
内存缓存 → 磁盘缓存(.pkl) → 重新计算
```

#### 2. **批量处理**
```python
# 批量向量化提高效率
vect_list = embedding.t2vect(text_list)  # 一次处理多个文本
```

#### 3. **增量更新**
```python
# 只向量化新增内容
new_vectors = embedding.t2vect(new_texts)
self.index.add(new_vectors)  # 增量添加到索引
```

### 📊 搜索性能优化

#### 1. **索引优化**
```python
# FAISS索引参数优化
self.index = faiss.IndexFlatIP(dimension)  # 内积相似度
```

#### 2. **查询优化**
```python
# 并行查询多个记忆层
threads = [
    Thread(target=core_mem.search, args=(msg, core_results)),
    Thread(target=long_mem.search, args=(msg, long_results)),
    Thread(target=knowledge_base.search, args=(msg, kb_results))
]
```

#### 3. **结果聚合**
```python
# 智能结果合并和排序
def aggregate_results(all_results):
    # 去重、排序、格式化
    return formatted_results
```

### 💾 存储优化

#### 1. **文件组织**
```
# 按时间和类型组织文件
data/agents/{char}/
├── core_mem.yml           # 核心记忆
├── memorys/               # 长期记忆
│   ├── 2024-01-15.yaml
│   └── 2024-01-15.pkl
└── data_base/             # 知识库
    ├── world_books.yaml
    └── tmp/
```

#### 2. **压缩存储**
```python
# pickle压缩存储向量数据
with open("vectors.pkl", "wb") as f:
    pickle.dump(vectors, f, protocol=pickle.HIGHEST_PROTOCOL)
```

#### 3. **清理机制**
```python
# 定期清理临时文件
def cleanup_temp_files():
    # 清理过期的缓存文件
    # 保留最近N天的文件
    pass
```

---

## 🔧 配置与扩展

### ⚙️ 配置参数

```yaml
# config.yaml - 记忆系统配置
Agent:
  # 基础设置
  long_memory: true           # 启用长期记忆
  is_core_mem: true          # 启用核心记忆
  lore_books: true           # 启用知识库
  
  # 搜索参数
  mem_thresholds: 0.38       # 记忆搜索阈值
  books_thresholds: 0.5      # 知识库搜索阈值
  scan_depth: 4              # 搜索结果数量
  
  # 检索增强
  is_check_memorys: true     # 启用语义过滤
  
  # 上下文管理
  context_length: 0          # 对话上下文长度 (0=无限制)
```

### 🔌 扩展接口

#### 1. **自定义记忆类型**
```python
class CustomMemory:
    def __init__(self, config):
        self.config = config
    
    def add_memory(self, data):
        # 自定义记忆添加逻辑
        pass
    
    def search(self, query):
        # 自定义搜索逻辑
        pass
```

#### 2. **插件化向量化**
```python
class CustomEmbedding:
    def t2vect(self, texts):
        # 自定义向量化算法
        return vectors
```

#### 3. **扩展存储后端**
```python
class CustomStorage:
    def save(self, data):
        # 支持数据库、云存储等
        pass
    
    def load(self):
        # 从自定义存储加载
        pass
```

### 📊 监控与调试

#### 1. **日志系统**
```python
# 详细的操作日志
Log.logger.info(f"加载记忆【{file}】")
Log.logger.error(f"记忆加载失败【{file_path}】")
```

#### 2. **性能监控**
```python
# 搜索耗时统计
start_time = time.time()
result = self.search(query)
end_time = time.time()
Log.logger.info(f"搜索耗时: {end_time - start_time:.3f}s")
```

#### 3. **数据统计**
```python
# 记忆数量统计
Log.logger.info(f"共加载{len(self.memorys_key)}条记忆")
Log.logger.info(f"向量索引大小: {len(self.vectors)}")
```

---

## 🎯 总结

MoeChat的记忆体系统是一个设计精良、功能完善的三层记忆架构，具有以下核心优势：

### ✅ 核心优势
1. **完整性**: 涵盖短期、长期、知识三个层面
2. **智能化**: LLM驱动的信息提取和标签生成
3. **高效性**: FAISS向量索引 + 多级缓存机制
4. **可扩展**: 插件化设计，支持自定义扩展
5. **可靠性**: 完整的持久化和错误恢复机制

### 🚀 技术特色
- **语义搜索**: 基于向量的深度语义理解
- **时间感知**: 支持自然语言时间查询
- **增量更新**: 智能的文件变化检测和更新
- **性能优化**: 多层次的缓存和索引优化
- **容错设计**: 单点故障不影响整体系统

### 📈 应用价值
该记忆系统不仅为MoeChat提供了强大的记忆能力，其设计理念和实现方案也为其他AI应用的记忆系统开发提供了宝贵的参考。

---

*文档版本: v1.0*  
*最后更新: 2024-01-15*