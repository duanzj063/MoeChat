# MoeChat 向量库改造方案

## 1. 项目背景

### 1.1 现状分析

当前MoeChat项目使用本地FAISS向量库进行向量存储和检索，具体实现包括：

- **Embedding模型**: 本地`nlp_gte_sentence-embedding_chinese-base`模型（维度未知）
- **向量库**: FAISS IndexFlatIP（内积相似度）
- **存储方式**: 本地文件系统（pickle缓存）
- **应用场景**: 
  - 核心记忆系统（`core_mem.py`）
  - 长期记忆系统（`long_mem.py`）
  - 知识库系统（`data_base.py`）

### 1.2 改造目标

- **Embedding模型**: 切换到远程`Qwen3-Embedding-0.6B`模型（1024维）
- **向量库**: 切换到远程PostgreSQL + pgvector扩展
- **配置灵活性**: 支持本地/远程模式动态切换
- **性能优化**: 利用PostgreSQL的索引和查询优化能力
- **可扩展性**: 支持分布式部署和大规模数据存储

## 2. 技术架构设计

### 2.1 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    MoeChat Application                      │
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐        │
│  │ Core Memory │  │ Long Memory │  │ Knowledge   │        │
│  │   System    │  │   System    │  │    Base     │        │
│  └─────────────┘  └─────────────┘  └─────────────┘        │
├─────────────────────────────────────────────────────────────┤
│                Vector Storage Interface                     │
│  ┌─────────────────────────────────────────────────────────┐│
│  │              VectorStore Abstract Layer                ││
│  └─────────────────────────────────────────────────────────┘│
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐           ┌─────────────────┐        │
│  │  Local FAISS    │           │ Remote PostgreSQL│        │
│  │  Implementation │           │  Implementation  │        │
│  └─────────────────┘           └─────────────────┘        │
├─────────────────────────────────────────────────────────────┤
│                Embedding Interface                          │
│  ┌─────────────────────────────────────────────────────────┐│
│  │              Embedding Abstract Layer                  ││
│  └─────────────────────────────────────────────────────────┘│
├─────────────────────────────────────────────────────────────┤
│  ┌─────────────────┐           ┌─────────────────┐        │
│  │ Local ModelScope│           │ Remote Xinference│        │
│  │  Implementation │           │  Implementation  │        │
│  └─────────────────┘           └─────────────────┘        │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 核心组件设计

#### 2.2.1 抽象接口层

```python
# utilss/vector_store.py
from abc import ABC, abstractmethod
from typing import List, Tuple, Optional
import numpy as np

class VectorStore(ABC):
    """向量存储抽象基类"""
    
    @abstractmethod
    def add_vectors(self, vectors: np.ndarray, texts: List[str], metadata: Optional[List[dict]] = None) -> List[str]:
        """添加向量和对应文本"""
        pass
    
    @abstractmethod
    def search(self, query_vector: np.ndarray, top_k: int = 5, threshold: float = 0.5) -> List[Tuple[str, float]]:
        """向量相似度搜索"""
        pass
    
    @abstractmethod
    def delete_by_ids(self, ids: List[str]) -> bool:
        """根据ID删除向量"""
        pass
    
    @abstractmethod
    def update_vector(self, vector_id: str, vector: np.ndarray, text: str, metadata: Optional[dict] = None) -> bool:
        """更新向量"""
        pass

class EmbeddingModel(ABC):
    """Embedding模型抽象基类"""
    
    @abstractmethod
    def encode(self, texts: List[str]) -> np.ndarray:
        """文本转向量"""
        pass
    
    @abstractmethod
    def get_dimension(self) -> int:
        """获取向量维度"""
        pass
```

#### 2.2.2 PostgreSQL向量库实现

```python
# utilss/pg_vector_store.py
import psycopg2
import numpy as np
from typing import List, Tuple, Optional
import uuid
import json

class PostgreSQLVectorStore(VectorStore):
    """PostgreSQL + pgvector 向量存储实现"""
    
    def __init__(self, config: dict, table_name: str):
        self.config = config
        self.table_name = table_name
        self.dimension = config.get('dimension', 1024)
        self._init_connection()
        self._create_table()
    
    def _init_connection(self):
        """初始化数据库连接"""
        self.conn = psycopg2.connect(**self.config['db_config'])
        self.conn.autocommit = True
    
    def _create_table(self):
        """创建向量表"""
        with self.conn.cursor() as cursor:
            cursor.execute(f"""
                CREATE TABLE IF NOT EXISTS {self.table_name} (
                    id VARCHAR(50) PRIMARY KEY,
                    vector vector({self.dimension}),
                    text TEXT NOT NULL,
                    metadata JSONB,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                );
            """)
            
            # 创建向量索引
            index_type = self.config.get('index_type', 'ivfflat')
            if index_type == 'ivfflat':
                lists = self.config.get('lists', 100)
                cursor.execute(f"""
                    CREATE INDEX IF NOT EXISTS {self.table_name}_vector_idx 
                    ON {self.table_name} USING ivfflat (vector vector_cosine_ops) 
                    WITH (lists = {lists});
                """)
            elif index_type == 'hnsw':
                ef_construction = self.config.get('ef_construction', 64)
                cursor.execute(f"""
                    CREATE INDEX IF NOT EXISTS {self.table_name}_vector_idx 
                    ON {self.table_name} USING hnsw (vector vector_cosine_ops) 
                    WITH (ef_construction = {ef_construction});
                """)
```

#### 2.2.3 远程Embedding模型实现

```python
# utilss/remote_embedding.py
import requests
import numpy as np
from typing import List
import time

class RemoteEmbeddingModel(EmbeddingModel):
    """远程Embedding模型实现"""
    
    def __init__(self, config: dict):
        self.url = config['url']
        self.api_key = config['api_key']
        self.model_name = config['model_name']
        self.dimension = config.get('dimension', 1024)
        self.timeout = config.get('timeout', 30)
        self.max_batch_size = config.get('max_batch_size', 20)
    
    def encode(self, texts: List[str]) -> np.ndarray:
        """批量文本转向量"""
        if not texts:
            return np.array([])
        
        # 分批处理大量文本
        all_embeddings = []
        for i in range(0, len(texts), self.max_batch_size):
            batch_texts = texts[i:i + self.max_batch_size]
            batch_embeddings = self._encode_batch(batch_texts)
            all_embeddings.extend(batch_embeddings)
        
        return np.array(all_embeddings)
    
    def _encode_batch(self, texts: List[str]) -> List[List[float]]:
        """单批次编码"""
        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }
        
        payload = {
            'model': self.model_name,
            'input': texts
        }
        
        response = requests.post(
            f'{self.url}/v1/embeddings',
            headers=headers,
            json=payload,
            timeout=self.timeout
        )
        
        if response.status_code == 200:
            result = response.json()
            return [item['embedding'] for item in result['data']]
        else:
            raise Exception(f"Embedding API error: {response.status_code} - {response.text}")
```

### 2.3 配置系统设计

#### 2.3.1 配置文件结构

```yaml
# config.yaml 新增配置项
VectorStore:
  # 向量库模式: local_faiss | remote_postgres
  mode: "remote_postgres"
  
  # 本地FAISS配置（兼容模式）
  local_faiss:
    cache_dir: "./tmp"
    index_type: "IndexFlatIP"
  
  # 远程PostgreSQL配置
  remote_postgres:
    db_config:
      host: "27.159.93.61"
      port: 5432
      database: "postgres"
      user: "root"
      password: "Fsti<#>2025"
    
    # 表名配置
    tables:
      core_memory: "moechat_core_memory"
      long_memory: "moechat_long_memory"
      knowledge_base: "moechat_knowledge"
    
    # 向量索引配置
    vector_config:
      dimension: 1024
      index_type: "ivfflat"  # ivfflat | hnsw
      lists: 100            # IVFFlat参数
      ef_construction: 64   # HNSW参数
      ef_search: 40         # HNSW搜索参数

Embedding:
  # Embedding模式: local_modelscope | remote_xinference
  mode: "remote_xinference"
  
  # 本地ModelScope配置（兼容模式）
  local_modelscope:
    model_path: "./utilss/models/nlp_gte_sentence-embedding_chinese-base"
    sequence_length: 100
  
  # 远程Xinference配置
  remote_xinference:
    url: "http://27.159.93.61:9997"
    api_key: "1"
    model_name: "Qwen3-Embedding-0.6B"
    dimension: 1024
    timeout: 30
    max_batch_size: 20
```

## 3. 实施计划

### 3.1 第一阶段：基础架构搭建

1. **创建抽象接口层**
   - 定义`VectorStore`和`EmbeddingModel`抽象基类
   - 设计统一的接口规范

2. **实现远程组件**
   - 开发`PostgreSQLVectorStore`类
   - 开发`RemoteEmbeddingModel`类
   - 实现基本的CRUD操作

3. **配置系统扩展**
   - 扩展`config.yaml`配置项
   - 更新配置加载逻辑

### 3.2 第二阶段：兼容性适配

1. **本地实现封装**
   - 将现有FAISS实现封装为`LocalFAISSVectorStore`
   - 将现有ModelScope实现封装为`LocalEmbeddingModel`

2. **工厂模式实现**
   - 创建`VectorStoreFactory`和`EmbeddingFactory`
   - 根据配置动态创建实例

3. **现有模块适配**
   - 修改`core_mem.py`、`long_mem.py`、`data_base.py`
   - 使用新的抽象接口替换直接调用

### 3.3 第三阶段：数据迁移和优化

1. **数据迁移工具**
   - 开发本地向量数据到PostgreSQL的迁移脚本
   - 支持增量迁移和数据验证

2. **性能优化**
   - PostgreSQL索引优化
   - 批量操作优化
   - 连接池管理

3. **测试和验证**
   - 单元测试覆盖
   - 性能基准测试
   - 功能回归测试

## 4. 关键技术点

### 4.1 向量维度兼容性

- **问题**: 现有本地模型维度与新模型维度不同
- **解决方案**: 
  - 配置中明确指定向量维度
  - 迁移时重新生成所有向量
  - 支持维度检查和验证

### 4.2 数据一致性

- **问题**: 分布式环境下的数据一致性
- **解决方案**:
  - 使用PostgreSQL事务保证ACID特性
  - 实现乐观锁机制
  - 添加数据版本控制

### 4.3 性能优化

- **索引策略**: 根据数据规模选择IVFFlat或HNSW索引
- **批量操作**: 支持批量插入和更新
- **连接管理**: 实现连接池避免频繁连接创建
- **缓存机制**: 热点数据本地缓存

### 4.4 容错处理

- **网络异常**: 实现重试机制和降级策略
- **服务不可用**: 支持本地模式回退
- **数据损坏**: 实现数据校验和修复机制

## 5. 风险评估和应对

### 5.1 技术风险

| 风险项 | 影响程度 | 应对措施 |
|--------|----------|----------|
| 远程服务不稳定 | 高 | 实现本地回退机制 |
| 数据迁移失败 | 中 | 完整的备份和回滚策略 |
| 性能下降 | 中 | 性能基准测试和优化 |
| 兼容性问题 | 低 | 充分的测试覆盖 |

### 5.2 运维风险

| 风险项 | 影响程度 | 应对措施 |
|--------|----------|----------|
| 数据库维护 | 中 | 定期备份和监控 |
| 网络延迟 | 低 | 就近部署和CDN加速 |
| 存储成本 | 低 | 数据压缩和清理策略 |

## 6. 预期收益

### 6.1 技术收益

- **可扩展性**: 支持大规模数据存储和检索
- **性能提升**: PostgreSQL优化的查询性能
- **维护性**: 统一的数据管理和备份
- **灵活性**: 支持多种部署模式

### 6.2 业务收益

- **用户体验**: 更快的响应速度和更准确的检索
- **运营效率**: 简化的数据管理和监控
- **成本控制**: 资源共享和优化利用

## 7. 总结

本改造方案通过引入抽象接口层，实现了向量库和Embedding模型的可插拔架构，既保证了向远程PostgreSQL的平滑迁移，又保持了对现有本地方案的兼容性。通过分阶段实施，可以最大程度降低改造风险，确保系统的稳定性和可用性。